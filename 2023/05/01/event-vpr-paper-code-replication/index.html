<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>论文代码复现(Event-VPR) | Gxyrious's Blog</title><meta name="keywords" content="科研,复现"><meta name="author" content="Gxyrious,2466445001@qq.com"><meta name="copyright" content="Gxyrious"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Background记录一下我第一次复现论文的过程中，遇到的各种问题和整体的步骤。这篇文章主要作为我自己的记录，并温习关于深度学习相关的知识点，一年后回看这些其实是个科研人的基本能力了，但是看到这些东西笔者还是挺怀念的，作为一个纯科研小白入门的第一篇从零复现的论文。 应该会涉及到如下知识点：  一部分论文的解读（一丢丢） dataset和dataloader怎么实现 model怎么实现，数据如何在">
<meta property="og:type" content="article">
<meta property="og:title" content="论文代码复现(Event-VPR)">
<meta property="og:url" content="http://gxyrious.github.io/2023/05/01/event-vpr-paper-code-replication/index.html">
<meta property="og:site_name" content="Gxyrious&#39;s Blog">
<meta property="og:description" content="Background记录一下我第一次复现论文的过程中，遇到的各种问题和整体的步骤。这篇文章主要作为我自己的记录，并温习关于深度学习相关的知识点，一年后回看这些其实是个科研人的基本能力了，但是看到这些东西笔者还是挺怀念的，作为一个纯科研小白入门的第一篇从零复现的论文。 应该会涉及到如下知识点：  一部分论文的解读（一丢丢） dataset和dataloader怎么实现 model怎么实现，数据如何在">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/image-20240621220121878.png">
<meta property="article:published_time" content="2023-05-01T07:48:44.000Z">
<meta property="article:modified_time" content="2026-01-19T03:40:29.000Z">
<meta property="article:author" content="Gxyrious">
<meta property="article:tag" content="科研">
<meta property="article:tag" content="复现">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/image-20240621220121878.png"><link rel="shortcut icon" href="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/b_177f95c202476c8fb7b2efb9f91c44ed.jpg"><link rel="canonical" href="http://gxyrious.github.io/2023/05/01/event-vpr-paper-code-replication/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文代码复现(Event-VPR)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-19 11:40:29'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/b_177f95c202476c8fb7b2efb9f91c44ed.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">39</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">50</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/image-20240621220121878.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Gxyrious's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文代码复现(Event-VPR)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-01T07:48:44.000Z" title="发表于 2023-05-01 15:48:44">2023-05-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-19T03:40:29.000Z" title="更新于 2026-01-19 11:40:29">2026-01-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>记录一下我第一次复现论文的过程中，遇到的各种问题和整体的步骤。这篇文章主要作为我自己的记录，并温习关于深度学习相关的知识点，一年后回看这些其实是个科研人的基本能力了，但是看到这些东西笔者还是挺怀念的，作为一个纯科研小白入门的第一篇从零复现的论文。</p>
<p>应该会涉及到如下知识点：</p>
<ol>
<li>一部分论文的解读（一丢丢）</li>
<li>dataset和dataloader怎么实现</li>
<li>model怎么实现，数据如何在forward之间传递的</li>
<li>loss函数有哪些，如何计算损失</li>
<li>如何使用optim优化参数</li>
<li>如何使用tensorboard记录训练过程</li>
</ol>
<p>关于event-camera和visual-place-recognition(vpr)。这是<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9760407">复现的论文</a>，主要用的<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/8288670">MVSEC</a>数据集。</p>
<p>我并没有完全按照原论文的做法，比如并没有使用<strong>EST Voxel Grid Representation</strong>层，而是直接用了个函数（即event-stream转voxel-grid的过程是写死的，而非可学习的），计算triplet-loss的时候也只用了最简单的方法。如果有人<del>不幸</del>看到这篇文章，并恰好也在做相关研究准备复现，请谨慎甄别。</p>
<h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>MVSEC数据集是在不同天气下（分别是day1, day2, night1, night2, night3）用事件相机录制的事件流，即一堆<code>(x, y, p, t)</code>，x和y表示光强改变的坐标，p表示方向，t表示时间戳。我们将连续的事件流划分在一起作为一个场景(subject)。</p>
<p>如何将连续的事件流划分为一个个场景是个超参数，按理说是有两种划分方式：</p>
<ol>
<li>以固定数量的事件流划分</li>
<li>以固定的时间间隔划分</li>
</ol>
<p>这两种方式应该对结果影响不大，我们让场景总数大致相等，论文中TABLE2表明划分完后，day1和day2的总数大致为11937和28583。这里主要用day2-train和day1-test，因为day2数据多，训练效果好，而night还需要结合两个不同天气的数据，比较麻烦。</p>
<p><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/tj-4-2/image-20240324230114606.png" alt="TABLE2"></p>
<p>试了一下拿15000作为固定数量的事件流划分还算合理，最后得到的数据集目录大致如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tree -L 1</span></span><br><span class="line">.</span><br><span class="line">├── 1506117898.9956346.npy</span><br><span class="line">├── 1506117899.8005185.npy</span><br><span class="line">├── ...</span><br><span class="line">└── 1506118159.997747.npy</span><br></pre></td></tr></table></figure>

<p>每个<code>npy</code>数据格式是<code>[fixed_length, 4]</code>，可以将每个场景可视化看一下，直接把所有事件描在图上就行，注意x和y的范围<code>[x,y]=[346,260]</code>是由采集的事件相机决定的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch, os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">root = <span class="string">&quot;&quot;</span></span><br><span class="line">filenames = [<span class="string">&quot;outdoor_day1&quot;</span>, <span class="string">&quot;outdoor_day2&quot;</span>]</span><br><span class="line"></span><br><span class="line">db_path = os.path.join(root, filenames[<span class="number">1</span>])</span><br><span class="line">sorted_list_dir = <span class="built_in">sorted</span>(os.listdir(db_path), key=<span class="keyword">lambda</span> x: <span class="built_in">float</span>(os.path.splitext(os.path.basename(x))[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">for</span> event_npy <span class="keyword">in</span> sorted_list_dir[<span class="number">400</span>:<span class="number">410</span>]: <span class="comment"># 文件名是一个场景的时间戳，可视化10张连续的场景</span></span><br><span class="line">    timestamp = <span class="built_in">float</span>(os.path.splitext(os.path.basename(event_npy))[<span class="number">0</span>])</span><br><span class="line">    frame = np.zeros((<span class="number">346</span>, <span class="number">260</span>))</span><br><span class="line">    events = np.load(os.path.join(db_path, event_npy))</span><br><span class="line">    <span class="built_in">print</span>(timestamp, <span class="built_in">len</span>(events))</span><br><span class="line">    x1 = events[:, <span class="number">1</span>][events[:, <span class="number">3</span>] == <span class="number">0.0</span>] <span class="comment"># p=0</span></span><br><span class="line">    y1 = events[:, <span class="number">2</span>][events[:, <span class="number">3</span>] == <span class="number">0.0</span>]</span><br><span class="line">    </span><br><span class="line">    x2 = events[:, <span class="number">1</span>][events[:, <span class="number">3</span>] == <span class="number">1.0</span>] <span class="comment"># p=1</span></span><br><span class="line">    y2 = events[:, <span class="number">2</span>][events[:, <span class="number">3</span>] == <span class="number">1.0</span>]</span><br><span class="line">    plt.scatter(x1, y1, s=<span class="number">0.1</span>, c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.scatter(x2, y2, s=<span class="number">0.1</span>, c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p>得到的效果如下，貌似反了，不过没事，这图还是能看出来是在大马路上开的。</p>
<p><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/tj-4-2/image-20240325000054813.png" alt="image-20240325000054813"></p>
<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>这里就得提到pytorch的Dataset和Dataloader了，一般先自定义一个类继承<code>torch.utils.data.Dataset</code>，然后实现三个内置函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YourDataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, /*自定义的参数*/</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">				self.xxx = xxx</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">				<span class="comment"># ...</span></span><br><span class="line">         <span class="keyword">return</span> anchor, pos_env, np.array(neg_envs)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.query)</span><br></pre></td></tr></table></figure>

<ol>
<li><code>__init__</code>就是初始化，一般如果是图片，我们会计算出每个图的路径保存给<code>self</code>，获取的时候再去加载；</li>
<li><code>__getitem__</code>是获取<strong>单个</strong>数据的方法，参数是<code>index</code>，这时候可以利用先前保存的路径去读取image、加载预处理过的<code>npy</code>文件等等；</li>
<li><code>__len__</code>是获取整个数据集的长度，也是<code>index</code>的取值范围，方便后续dataloader批量读取；</li>
</ol>
<p>dataset是可以直接取索引的，用的<code>__getitem__</code>方法。</p>
<hr>
<p>dataset一般得传给dataloader，从而实现以<code>batchsize</code>大小读取。你也可以自定义loader，然后用yield方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">YourDataLoader</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, batchsize=<span class="number">1</span>, device=<span class="string">&quot;cuda:0&quot;</span></span>):</span><br><span class="line">        self.device = device</span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.loader = torch.utils.data.DataLoader(</span><br><span class="line">            dataset,</span><br><span class="line">            batch_size=batchsize,</span><br><span class="line">            num_workers=<span class="number">4</span>,</span><br><span class="line">        )</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> self.loader:</span><br><span class="line">            <span class="keyword">yield</span> data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以直接测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_dataset = YourDataset(xxx)</span><br><span class="line">    <span class="built_in">print</span>(dataset[-<span class="number">1</span>][<span class="number">0</span>], dataset[-<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">    train_loader = YourDataLoader(train_dataset, batchsize=<span class="number">4</span>, device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> tqdm.tqdm(train_loader):</span><br><span class="line">          	<span class="keyword">import</span> pdb; pdb.set_trace()</span><br></pre></td></tr></table></figure>

<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>一般Model需要继承<code>nn.Module</code>类，在<code>__init__</code>中定义一些自己的变量，在<code>forward</code>定义数据通过模型的过程。下面的这个Model例子中，输入vox的shape为<code>[4, 5, 260, 346]</code>，4是batchsize，<code>[5, 260, 346]</code>是voxel grid的形状，通过上述数据集中的<code>events_to_voxel_grid()</code>函数将事件流转换而来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriptor</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">				<span class="comment"># dimension of voxel will be C x 2 x H x W</span></span></span><br><span class="line"><span class="params">        voxel_dimension=(<span class="params"><span class="number">5</span>,<span class="number">346</span>,<span class="number">260</span></span>),</span></span><br><span class="line"><span class="params">				<span class="comment"># dimension of crop before it goes into classifier</span></span></span><br><span class="line"><span class="params">        crop_dimension=(<span class="params"><span class="number">224</span>, <span class="number">224</span></span>),</span></span><br><span class="line"><span class="params">        mlp_layers=[<span class="number">1</span>, <span class="number">30</span>, <span class="number">30</span>, <span class="number">1</span>],</span></span><br><span class="line"><span class="params">        activation=nn.LeakyReLU(<span class="params"></span>),</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        nn.Module.__init__(self)</span><br><span class="line">        self.voxel_dimension = voxel_dimension</span><br><span class="line">        self.quantization_layer = QuantizationLayer(voxel_dimension, mlp_layers, activation)</span><br><span class="line">        self.resnet34 = ResNet34(input_channels=voxel_dimension[<span class="number">0</span>])</span><br><span class="line">        self.crop_dimension = crop_dimension</span><br><span class="line">        self.vlad = NetVLAD2(num_clusters=<span class="number">32</span>, dim=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">crop_and_resize_to_resolution</span>(<span class="params">self, x, output_resolution=(<span class="params"><span class="number">224</span>, <span class="number">224</span></span>)</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">if</span> H &gt; W:</span><br><span class="line">            h = H // <span class="number">2</span></span><br><span class="line">            x = x[:, :, h - W // <span class="number">2</span>:h + W // <span class="number">2</span>, :]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            h = W // <span class="number">2</span></span><br><span class="line">            x = x[:, :, :, h - H // <span class="number">2</span>:h + H // <span class="number">2</span>]</span><br><span class="line">        x = F.interpolate(x, size=output_resolution)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, vox</span>): <span class="comment"># (total_event_number, 5)</span></span><br><span class="line">        <span class="comment"># vox: [4, 5, 260, 346]</span></span><br><span class="line">        vox_cropped = self.crop_and_resize_to_resolution(vox, self.crop_dimension)</span><br><span class="line">        <span class="comment"># vox_cropped: [4, 5, 224, 224]</span></span><br><span class="line">        <span class="comment"># modified resnet34</span></span><br><span class="line">        pred = self.resnet34.forward(vox_cropped.to(dtype=torch.float32)) </span><br><span class="line">        <span class="comment"># pred: [4, 512, 7, 7]</span></span><br><span class="line">        embedded_x = self.vlad(pred)</span><br><span class="line">        <span class="keyword">return</span> embedded_x <span class="comment"># (4, 16384)</span></span><br></pre></td></tr></table></figure>

<p>也可以在这里面嵌套各个其他的模型，例如resnet34，这是当时改过最后几层的一个resnet34，不过这样改貌似不是最好的方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet34</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels=<span class="number">5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet34, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.resnet34 = resnet34(weights=ResNet34_Weights.DEFAULT)</span><br><span class="line">        self.resnet34.conv1 = nn.Conv2d(input_channels, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Remove avgpool, flatten, and fc layers</span></span><br><span class="line">        <span class="comment"># self.resnet34.avgpool = nn.Identity()</span></span><br><span class="line">        <span class="comment"># self.resnet34.fc = nn.Identity()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.resnet34.conv1(x)</span><br><span class="line">        x = self.resnet34.bn1(x)</span><br><span class="line">        x = self.resnet34.relu(x)</span><br><span class="line">        x = self.resnet34.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.resnet34.layer1(x)</span><br><span class="line">        x = self.resnet34.layer2(x)</span><br><span class="line">        x = self.resnet34.layer3(x)</span><br><span class="line">        x = self.resnet34.layer4(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h1 id="Loss-amp-Optim"><a href="#Loss-amp-Optim" class="headerlink" title="Loss &amp; Optim"></a>Loss &amp; Optim</h1><p>论文中使用的是Triplet Loss，它的计算需要一个**三元组&lt;a, p, n&gt;**：</p>
<ol>
<li><p>a, anchor表示训练样本。</p>
</li>
<li><p>p, positive表示预测为正样本。</p>
</li>
<li><p>n, negative表示预测为负样本。</p>
</li>
</ol>
<p>Triplet Loss的目的是减少positive与anchor之间的距离，扩大negative与anchor之间的距离。基于上述三元组，可以构建一个positive pair &lt;a, p&gt;和一个negative pair &lt;a, n&gt;。triplet loss的目的是在一定的margin上把positive pair和negative pair分开。</p>
<p><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/tj-4-2/2019080115443418.png"></p>
<p>具体的做法是，针对vpr的情况，如下：</p>
<ol>
<li>每个样本是一个<code>[4, 16384]</code>的向量，其中4是batchsize。对于每个16384的向量，它的来源是某一个地点的事件流。例如对于每个Anchor，与它距离超过10米的认为是positive的，而超过25的认为是negative。</li>
<li>这样就可以得到一系列三元组，我们把所有<strong>地点</strong>和<strong>事件流</strong>划分为query和database，对于每个query，将database中的事件流划分为positive和negative。很显然negative的数量会远大于positive，且它们都会有一定数量，这些都在dataset中预处理了，下述dataset在每次<code>__getitem__</code>的时候，获取的都是1个Anchor、1个positive和<code>n_sample</code>个negative。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MVSEC_Single_Train_Dataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dtrain=<span class="number">2</span>, th_pos=<span class="number">10</span>, th_neg=<span class="number">25</span>, n_sample=<span class="number">10</span></span>):</span><br><span class="line">        <span class="comment"># dq, d1, d2分别是训练集的query和database，dtq和dtb是测试集的query和database</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dtrain = dtrain</span><br><span class="line">        self.th_pos, self.th_neg = th_pos, th_neg</span><br><span class="line">        self.n_sample = n_sample</span><br><span class="line">        self.query, self.db = self.get_xyt_list(dtrain)</span><br><span class="line">        self.triplet_train_list = self.get_triplet_train()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        triplet_train =  self.triplet_train_list[index]</span><br><span class="line">        x, y, timestamp = self.query[triplet_train[<span class="number">0</span>]]</span><br><span class="line">        anchor = np.load(Config.events_root + filenames[self.dtrain] + <span class="string">&#x27;/&#x27;</span> + <span class="built_in">str</span>(timestamp) + <span class="string">&#x27;.npy&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        e0pos = triplet_train[<span class="number">1</span>]</span><br><span class="line">        best_pos = np.random.choice(e0pos, size=<span class="number">1</span>, replace=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line">        x, y, timestamp = self.db[best_pos]</span><br><span class="line">        pos_env = np.load(Config.events_root + filenames[self.dtrain] + <span class="string">&#x27;/&#x27;</span> + <span class="built_in">str</span>(timestamp) + <span class="string">&#x27;.npy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        e0neg = triplet_train[<span class="number">2</span>]</span><br><span class="line">        e0neg_selected = np.random.choice(e0neg, size=self.n_sample, replace=<span class="literal">False</span>)</span><br><span class="line">        neg_envs = []</span><br><span class="line">        <span class="keyword">for</span> nega <span class="keyword">in</span> e0neg_selected:</span><br><span class="line">            neg_envs.append(np.load(Config.events_root + filenames[self.dtrain] + <span class="string">&#x27;/&#x27;</span> + <span class="built_in">str</span>(self.db[nega][<span class="number">2</span>]) + <span class="string">&#x27;.npy&#x27;</span>))</span><br><span class="line">        <span class="keyword">return</span> events_to_voxel_grid(anchor), events_to_voxel_grid(pos_env), np.array([events_to_voxel_grid(nega) <span class="keyword">for</span> nega <span class="keyword">in</span> neg_envs])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.query)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_single_xyt</span>(<span class="params">self, loc, ts_comb, count</span>):</span><br><span class="line">        t_min, t_max = loc[<span class="number">0</span>, <span class="number">2</span>], loc[-<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        idx_begin = np.argmax(ts_comb &gt; t_min)</span><br><span class="line">        idx_end = np.argmin(ts_comb &lt; t_max) - <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        idx_selected = np.<span class="built_in">round</span>(np.linspace(idx_begin, idx_end, count)).astype(<span class="built_in">int</span>)</span><br><span class="line">        t_selected = ts_comb[idx_selected]</span><br><span class="line">        </span><br><span class="line">        new_x = np.interp(t_selected, loc[:, <span class="number">2</span>], loc[:, <span class="number">0</span>])</span><br><span class="line">        new_y = np.interp(t_selected, loc[:, <span class="number">2</span>], loc[:, <span class="number">1</span>])</span><br><span class="line">        </span><br><span class="line">        xyt_comb = np.column_stack((new_x, new_y, t_selected))</span><br><span class="line">        <span class="keyword">return</span> xyt_comb</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_xyt_list</span>(<span class="params">self, dtrain</span>):</span><br><span class="line">        loc = np.load(Config.gps_root + filenames[dtrain] + <span class="string">&#x27;.npy&#x27;</span>) <span class="comment"># 得是np.array</span></span><br><span class="line">        ts_comb = get_calag_timestamps_sorted(dtrain)</span><br><span class="line">        </span><br><span class="line">        xyt_comb = self.get_single_xyt(loc, ts_comb, Config.subject_len[dtrain])</span><br><span class="line">        permuted = np.random.permutation(xyt_comb)</span><br><span class="line">        query, database = permuted[:<span class="built_in">int</span>(<span class="built_in">len</span>(permuted)*<span class="number">0.3</span>)], permuted[<span class="built_in">int</span>(<span class="built_in">len</span>(permuted)*<span class="number">0.3</span>):]</span><br><span class="line">        <span class="keyword">return</span> query, database</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_triplet_train</span>(<span class="params">self</span>):</span><br><span class="line">        triplet_train_list = []</span><br><span class="line">        <span class="keyword">for</span> idx, (qx, qy, qt) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm.tqdm(self.query, ncols=<span class="number">50</span>)):</span><br><span class="line">            tmp = (self.db[:, <span class="number">0</span>] - qx) ** <span class="number">2</span> + (self.db[:, <span class="number">1</span>] - qy) ** <span class="number">2</span></span><br><span class="line">            e0pos = np.where(tmp &lt; self.th_pos)[<span class="number">0</span>]</span><br><span class="line">            e0neg = np.where(tmp &gt; self.th_neg)[<span class="number">0</span>]</span><br><span class="line">            triplet_train_list.append([idx, e0pos, e0neg])</span><br><span class="line">        <span class="keyword">return</span> triplet_train_list</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>在训练时，分别让<code>anchor, pos, negs</code>通过模型，得到向量后，计算它们的distan；优化器选择的是Adam，<del>反正据说不确定的话选它就完事了（）</del>。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">distan = torch.nn.TripletMarginWithDistanceLoss(margin=Config.margin, distance_function=cosine_distance)</span><br><span class="line">optim = torch.optim.Adam(params=discriptor.parameters(), lr=Config.lr)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">train_loader, net, distan, optim, epoch</span>):</span><br><span class="line">    net = net.train()</span><br><span class="line">    losses = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> anchor, pos, negs <span class="keyword">in</span> tqdm.tqdm(train_loader, ncols=<span class="number">50</span>):</span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        disc_anchor = net(anchor.to(Config.device)) <span class="comment"># [4, 16384]</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            disc_pos = net(pos.to(Config.device)) <span class="comment"># [4, 16384]</span></span><br><span class="line">            disc_negs_merged = net(negs_merged.to(Config.device))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(disc_negs.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># 计算若干次loss，具体受到negs数量的影响</span></span><br><span class="line">            loss += distan(disc_anchor, disc_pos, disc_negs[:, idx, :])</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        losses += loss</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125;\t Loss: &#123;&#125; \t \n&#x27;</span>.<span class="built_in">format</span>(epoch, losses / <span class="built_in">len</span>(train_loader)))</span><br><span class="line">    <span class="keyword">return</span> losses / <span class="built_in">len</span>(train_loader)</span><br></pre></td></tr></table></figure>

<h1 id="TensorBoard"><a href="#TensorBoard" class="headerlink" title="TensorBoard"></a>TensorBoard</h1><p>这种记录的工具还挺多，wandb也挺好用，不过需要联网。挺喜欢tensorboard的，直接pip装就好。启动tensorboard使用如下命令，logdir是SummaryWriter的参数。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --port=8888 --logdir=<span class="variable">$&#123;Config.log&#125;</span></span><br></pre></td></tr></table></figure>

<p>给一个使用的示例，附带学习率的变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(Config.log)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=Config.lrStep, gamma=Config.lrGamma) <span class="comment"># 学习率的变化工具</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;loss&quot;</span>, loss, epoch)</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;lr&quot;</span>, scheduler.get_last_lr()[<span class="number">0</span>], epoch) <span class="comment"># 记录一下学习率</span></span><br><span class="line">    writer.add_scalars(<span class="string">&quot;recall&quot;</span>, tag_scalar_dict=&#123;</span><br><span class="line">        <span class="string">&quot;recall_1&quot;</span>: acc1,</span><br><span class="line">        <span class="string">&quot;recall_5&quot;</span>: acc5,</span><br><span class="line">        <span class="string">&quot;recall_10&quot;</span>: acc10,</span><br><span class="line">    &#125;, global_step=epoch)</span><br></pre></td></tr></table></figure>

<hr>
<p><del>希望并不聪明的我科研之路一些顺利</del></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://gxyrious.github.io">Gxyrious</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://gxyrious.github.io/2023/05/01/event-vpr-paper-code-replication/">http://gxyrious.github.io/2023/05/01/event-vpr-paper-code-replication/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://gxyrious.github.io" target="_blank">Gxyrious's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E7%A0%94/">科研</a><a class="post-meta__tags" href="/tags/%E5%A4%8D%E7%8E%B0/">复现</a></div><div class="post_share"><div class="social-share" data-image="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/image-20240621220121878.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/13/common-operation-records/"><img class="prev-cover" src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-m9y9j1_1920x1080.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">常见操作记录</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/11/ai-intro/"><img class="next-cover" src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/1_1679045695.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">人工智能浅学</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/b_177f95c202476c8fb7b2efb9f91c44ed.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Gxyrious</div><div class="author-info__description">你看 月亮正对着你笑</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">39</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">50</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Gxyrious"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Gxyrious" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:chang.liu.me@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">日常瞎写，自我记录，不定更新</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Background"><span class="toc-number">1.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dataset"><span class="toc-number">2.</span> <span class="toc-text">Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">2.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implementation"><span class="toc-number">2.2.</span> <span class="toc-text">Implementation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Model"><span class="toc-number">3.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Loss-amp-Optim"><span class="toc-number">4.</span> <span class="toc-text">Loss &amp; Optim</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TensorBoard"><span class="toc-number">5.</span> <span class="toc-text">TensorBoard</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/01/21/algorithm-valued-problem/" title="算法题记录"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-exql8w_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法题记录"/></a><div class="content"><a class="title" href="/2026/01/21/algorithm-valued-problem/" title="算法题记录">算法题记录</a><time datetime="2026-01-21T13:35:00.000Z" title="发表于 2026-01-21 21:35:00">2026-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/21/algorithm-to-enhance-dp/" title="动态规划题型整理"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-6d6mk7_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="动态规划题型整理"/></a><div class="content"><a class="title" href="/2026/01/21/algorithm-to-enhance-dp/" title="动态规划题型整理">动态规划题型整理</a><time datetime="2026-01-21T13:31:00.000Z" title="发表于 2026-01-21 21:31:00">2026-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/21/algorithm-to-enhance/" title="算法题小整理"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-e7ek7k_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法题小整理"/></a><div class="content"><a class="title" href="/2026/01/21/algorithm-to-enhance/" title="算法题小整理">算法题小整理</a><time datetime="2026-01-21T04:12:00.000Z" title="发表于 2026-01-21 12:12:00">2026-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/18/leetcode-weekly-contest/" title="力扣周赛记录"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-28j5r6_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="力扣周赛记录"/></a><div class="content"><a class="title" href="/2026/01/18/leetcode-weekly-contest/" title="力扣周赛记录">力扣周赛记录</a><time datetime="2026-01-17T16:00:00.000Z" title="发表于 2026-01-18 00:00:00">2026-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/14/java-garbage-collection/" title="Java垃圾回收"><img src="https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/wallpapers/wallhaven-28j5r6_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java垃圾回收"/></a><div class="content"><a class="title" href="/2025/07/14/java-garbage-collection/" title="Java垃圾回收">Java垃圾回收</a><time datetime="2025-07-13T16:22:43.000Z" title="发表于 2025-07-14 00:22:43">2025-07-14</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://gxyrious.oss-cn-hangzhou.aliyuncs.com/img/blog/image-20240621220121878.png')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2026 By Gxyrious</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script></div></body></html>